# -*- coding: utf-8 -*-
"""Churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14q5R60EVlA-5Yi-i4-QvxJHoTCXeJkD_

Customer Churn Analysis
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

"""Data source: https://www.kaggle.com/datasets/ankitverma2010/ecommerce-customer-churn-analysis-and-prediction/data

1. Data Loading:
"""

c=pd.read_csv('/content/customer .csv')

c_copy=c.copy() # copy of the original dataset is created which can be used for future references

c.head(2) # reading first 2 rows

c.tail(2) #reading last 2 rows

"""2. Exploratory Data Analysis"""

c.shape # reading dimensions of the dataset

c.info()

c.describe() # statistical summary

c.columns

c.nunique() # count of unique values per column

"""a. No.of customers based on login device"""

c['PreferredLoginDevice'].value_counts()

"""Most of the customers prefer mobile phone

b. Customers based on gender
"""

c['Gender'].value_counts()

"""Comparatively, male customers are more

c. customers churned based on login device
"""

plt.figure(figsize=(5,3))
sns.set(font_scale=0.7)
s=sns.countplot(data=c,x='PreferredLoginDevice',hue='Churn')
plt.ylabel('Number of customers')
for i in s.containers:
  s.bar_label(i)

"""Only small amount of customers have churned

d. gender vs churn
"""

plt.figure(figsize=(5,3))
sns.set(font_scale=0.7)
s=sns.countplot(data=c,x='Gender',hue='Churn')
plt.ylabel('Number of customers')
for i in s.containers:
  s.bar_label(i)

"""e. customers churned from different cities"""

sns.set_style('whitegrid')
f=sns.FacetGrid(data=c,col ='Gender',row='Churn')
f.map_dataframe(sns.countplot,x='CityTier')

"""City 1 has more customers than from other 2 city tiers

f. customers churned from different devices used
"""

sns.set_style('whitegrid')
h=sns.FacetGrid(data=c,col='Gender',row='Churn')
h.map_dataframe(sns.countplot,x='PreferredLoginDevice')

"""g. time spent on app by different customers based on their gender"""

plt.figure(figsize=(5,3))
sns.set(font_scale=0.7)
s=sns.countplot(data=c,x='HourSpendOnApp',hue='Gender')
plt.ylabel('Number of customers')
for i in s.containers:
  s.bar_label(i)

"""Maximum hours spent is 4 , but 3 hrs is the maximum duration spent by each customer

h. time spent vs satisfaction score
"""

plt.figure(figsize=(6,4))
sns.set(font_scale=0.5)
s=sns.barplot(data=c,x='SatisfactionScore',y='HourSpendOnApp',hue='Gender',errorbar=None)
sns.move_legend(s,"center")
for i in s.containers:
  s.bar_label(i)

"""i.no.of complains raised by customers"""

plt.figure(figsize=(4,3))
sns.set(font_scale=0.6)
s=sns.countplot(data=c,x='Complain',hue='Gender')
for i in s.containers:
  s.bar_label(i)

"""j. coupons used"""

plt.figure(figsize=(7,6))
sns.set(font_scale=0.6)
s=sns.countplot(data=c,x='CouponUsed',hue='Gender')
for i in s.containers:
  s.bar_label(i)

"""k. payment mode vs gender"""

plt.figure(figsize=(5,4))
sns.set(font_scale=0.5)
s=sns.countplot(data=c,x='PreferredPaymentMode',hue='Gender')
for i in s.containers:
  s.bar_label(i)

"""Majority prefers debit card for payment

l. cashback amount vs order categories based on gender
"""

plt.figure(figsize=(7,6))
sns.set(font_scale=0.5)
s=sns.barplot(data=c,x='PreferedOrderCat',y='CashbackAmount',hue='Gender',errorbar=None)
for i in s.containers:
  s.bar_label(i)

"""m. payment mode vs cashback amt"""

plt.figure(figsize=(7,6))
sns.set(font_scale=0.5)
s=sns.barplot(data=c,x='PreferredPaymentMode',y='CashbackAmount',hue='Gender',errorbar=None)
for i in s.containers:
  s.bar_label(i)

"""n. order count vs gender"""

plt.figure(figsize=(5,4))
sns.set(font_scale=0.5)
s=sns.countplot(data=c,x='OrderCount',hue='Gender')
for i in s.containers:
  s.bar_label(i)

"""Data Cleaning"""

print('null values:',c.isnull().any().sum())
print('nan values:',c.isna().any().sum())
print('duplicates:',c.duplicated().any().sum())

"""Null values are dropped"""

c=c.dropna()

l=[]
for i in range(len(c)):
  l.append(i)
c.index=l

print('null values:',c.isnull().any().sum())
print('nan values:',c.isna().any().sum())
print('duplicates:',c.duplicated().any().sum())

"""Removing unnecessary columns"""

c=c.drop(columns=['CustomerID'])

"""Feature Engineering"""

c1=c.loc[:,['PreferredLoginDevice','PreferredPaymentMode','Gender','PreferedOrderCat','MaritalStatus']]

c_f=c.drop(columns=c1.columns)

from sklearn.preprocessing import LabelEncoder
c_cd=c1.apply(LabelEncoder().fit_transform)

C=pd.concat([c_f,c_cd],axis=1)

"""Feature Selection"""

# separate data into feature and target:

x=C.drop(columns='Churn') # feature
y=C['Churn'] # Target is churn

correlation_values = x.apply(lambda feature: np.abs(np.corrcoef(feature, y)[0, 1]))

correlation_values

sorted_features = correlation_values.sort_values(ascending=False)

sorted_features

k = 10
selected_features = sorted_features.index[:k] # why .index because:- x[columns in selected_features. corr gives the values,we need only column names]

selected_features

sns.heatmap(x[selected_features].corr(), annot=True, fmt='.2f', linewidths=0.5)

sorted_features[:k]

selected_features

plt.figure(figsize=(11,11))
sns.set(font_scale=0.5)
v=sns.barplot(x=selected_features, y=sorted_features[:k])
for i in v.containers:
  v.bar_label(i)
plt.xlabel('Selected featues')
plt.ylabel('Values')

"""Above are the top 10 features that act as factors of customers' churn

Model Building
"""

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

selected_features

"""the top 10 features are selected for model building"""

x=x.loc[:,['Tenure', 'Complain', 'NumberOfDeviceRegistered', 'DaySinceLastOrder',
       'MaritalStatus', 'PreferedOrderCat', 'SatisfactionScore',
       'WarehouseToHome', 'NumberOfAddress', 'CityTier']]

std=StandardScaler() # standardising the features
X=std.fit_transform(x)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

print('x_train.shape:',x_train.shape,'x_test.shape:',x_test.shape)

print('y_train.shape:',y_train.shape,'y_test.shape:',y_test.shape)

from sklearn.model_selection import GridSearchCV

models={
    'log_r':{
        'model':LogisticRegression(),
        'params':{

        }
    },
    'KNC':{
        'model':KNeighborsClassifier(),
        'params':{
            'n_neighbors':[2,5,10,12,15,20]
        }
    },
    'RFC':{
        'model':RandomForestClassifier(),
        'params':{
            'n_estimators':[1,2,3,4,5,6,7,8,9,10,12,15,20]
        }
    }
}

from sklearn.model_selection import ShuffleSplit

scores=[]
cv=ShuffleSplit(n_splits=5,test_size=0.2,random_state=0)
for i,j in models.items():
  gs=GridSearchCV(j['model'],j['params'],cv=cv,return_train_score=False)
  gs.fit(x,y)
scores.append({
    'model':i,
    'best score':gs.best_score_,
    'best parameter':gs.best_params_
})

df=pd.DataFrame(scores,columns=['model','best score','best parameter'])
df

"""Among the models, Random Forest Classifier is chosen due to its highest score"""

from sklearn.model_selection import cross_val_score
cv=ShuffleSplit(n_splits=5,test_size=0.2)
s=cross_val_score(RandomForestClassifier(n_estimators=20),x,y,cv=cv)
print('Average Accuracy : {}%'.format(round(sum(s)*100/len(s)), 3))

"""The accuracy obtained using model built by Random Forest Classificatier algorithm is around 97%. This can be used for predicting customer churn in the future."""

rfc=RandomForestClassifier(n_estimators=20)
rfc.fit(x_train,y_train)

#Features:- ['Tenure', 'Complain', 'NumberOfDeviceRegistered', 'DaySinceLastOrder',
 #      'MaritalStatus', 'PreferedOrderCat', 'SatisfactionScore',
 #      'WarehouseToHome', 'NumberOfAddress', 'CityTier']

print(rfc.predict([[4.0,1,3,5.0,2,2,2,6.0,9,3]]))
print(rfc.predict([[0.0,0,4,3.0,2,2,5,15.0,8,3]]))
print(rfc.predict([[23.0,0,5,9.0,1,2,4,9.0,4,3]]))

from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay

pred=rfc.predict(x_test)

print(classification_report(pred,y_test))